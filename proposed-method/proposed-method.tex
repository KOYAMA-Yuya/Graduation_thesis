%!TEX root = ../thesis.tex
\section{オフライン学習}

本章では, 本研究の基盤となるオフライン模倣学習の概念と, 自動でデータセットを収集するシステムついて述べる. 
オフライン模倣学習とは，熟練者や既存の制御則による行動データを事前に蓄積し，
そのデータセットのみを用いて方策を学習する手法である．オンライン学習とは異なり，学習時間短縮の面で利点がある．
しかし, 髙橋らによる先行研究において示された通り, 経路追従の堅牢性を高めるには, 
目標経路から逸脱した位置, 姿勢の誤差を含む多様なデータが必要となる. 
従来の手法では, これらの多様な状態を作り出すために, ロボットを一台ずつ手動で配置し直してデータを取得していた. 
一方で,これらのデータをロボットの走行中に自動的に収集し,そのまま学習に用いるシステムの構築および評価については,
十分な検証が行われていない.そこで本研究では, ロボットが経路追従走行を行いながら, 
多様な視覚情報と行動データを同一タイミングで自動収集するシステムを構築し, 
データ収集から学習までの工程を効率化するシステムの有効性を検証する. 

\section{自動データ収集システム}

本研究で構築したシステムは, 先行研究 \cite{okada-si2020} 同様にロボットの走行中に複数台のカメラ画像と制御入力を同期して
記録するものである. データ収集には, 先行研究に基づくシミュレーション環境およびルールベース制御器を用いる. 

\figref{Fig:collect-data2}に示すようにロボットを目標経路に沿って走行させ, 
走行中に取得した複数台のカメラ画像と, ルールベース制御器によるナビゲーション出力である角速度をペアとして保存する. 
データ収集は, ロボットが0.2\,m走行するごとに行い, 取得した画像は64$\times$48画素にリサイズした. 
制御入力: 並進速度を 0.2 m/s の一定値とし, ルールベース制御器から出力される角速度のみを学習対象とする. 


本研究では, 先行研究における実験を再現可能とするため, ロボット走行中に複数台のカメ
ラ画像と行動データを同一タイミングで取得・保存可能なデータ収集システムを構築した. 構
築したシステムでは, 前方に向けて配置した 3 台もしくは 9 台の RGB カメラ画像と, それに対応するロボッ
トの角速度指令を同期して取得し, 学習用データセットとして自動的に保存することができる.

\section{視覚情報の構成と学習設定}
本手法の特徴は, 複数台のカメラから得られる広範な視覚情報を学習入力として扱う点にある. 実環境への適用を想定し, 
カメラの台数や配置が学習性能に与える影響を検証する. 
さらに, システム構成を簡略化するため, 少数の物理カメラ画像から射影変換を用いて視野情報を拡張する処理を導入する. 
これにより, ハードウェアの制約と学習性能の両立を図る. 
収集されたデータセットを用いたオフライン学習は, バッチサイズ16のミニバッチ学習により行う. 
エポック数は実験条件に応じて最適化し, 少量のデータセットでも過学習を抑え, 安定した経路追従モデルが獲得できるよう設定した. 

\begin{figure}[h]
  \centering
  \includegraphics[keepaspectratio, scale=0.35]{images/collect-data.png}
  \caption{Method of collecting data around the target route}
  \label{Fig:collect-data2}
\end{figure}